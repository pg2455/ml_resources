{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical, we will be using PyTorch's `prune` module to  to implement different types of pruning mechanism on a CNN trained to detect land use from satellite images. We will be using [EuroSat (RGB)](https://github.com/phelber/eurosat) dataset for this task. This tutorial will work through the following steps - \n",
    "\n",
    "1. Load and explore EuroSAT (RGB) dataset containing RGB images. Note that there is a larger sized counterpart to EuroSAT dataset with multispectral (MS) images. For this tutorial, we will be using RGB images instead. Satellite MS images are handeled conveniently by [`torchgeo`](https://github.com/microsoft/torchgeo). EuroSAT(MS) is also available through `torchgeo.datasets`. \n",
    "2. Create and train a Deep CNN on EuroSAT (RGB). \n",
    "3. Explore various pruning techniques and the their pareto frontier, i,e., trade-off between accuracy and sparsity. Specifically, we will look at \n",
    "    - Random unstructured pruning with prune rate applied locally\n",
    "    - L1 unstructured pruning with prune rate applied locally\n",
    "    - L1 unstructured pruning with prune rate applied globally\n",
    "    - L1 structured pruning\n",
    "\n",
    "**WARNING**: \n",
    "\n",
    "1. This tutorial requires retraining the pruned model. Each step of retraining will be time consuming. To alleviate that, this tutorial comes with the trained pruned model in `./models/best_DeepCNN.ckpt`. A function `load_unpruned_model` loads the trained unpruned model. Thus, you can skip the training of the unpruned model. \n",
    "\n",
    "2. First 2 steps are standard to constructing any machine learning models. Therefore, we can skim through these steps. There are still some TODOs in case someone wants to run the tutorial from start to finish.\n",
    "\n",
    "3. Jump over to **B. Network Pruning** to start learning how to prune models in PyTorch\n",
    "\n",
    "4. If the kernel dies in between, the trained pruned model are saved in `./models` with their corresponding postfixes. Loading a pruned model in PyTorch requires some workarounds. Follow the code in `train` to learn more about details on how to do so. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Standard training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.utils.prune as prune #### NOTE: `prune` module need to be loaded like this only. https://github.com/pytorch/pytorch/issues/32483\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# fix seed for reproducibility \n",
    "rng = np.random.RandomState(1)\n",
    "torch.manual_seed(rng.randint(np.iinfo(int).max))\n",
    "\n",
    "# it is a good practice to define `device` globally\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU -> using CPU:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There is no train, val, test split in this dataset, so we need to create it ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.datasets.EuroSAT(root=\"./data\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.EuroSAT(root='./data') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the documentation of [torchvision.datasets.EuroSAT](https://pytorch.org/vision/stable/generated/torchvision.datasets.EuroSAT.html#torchvision.datasets.EuroSAT) to understand the data structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What is the type of data?\\n\", type(data))\n",
    "print(\"\\nHow does an observation in data look like?\\n\", data[0])\n",
    "print(\"Each obseervation is a tuple of (image, label)\")\n",
    "print(\"\\nHow does an image in data look like?\", data[0][0])\n",
    "print(\"Each image is a 3x64x64 tensor\")\n",
    "print(\"\\nHow many observations are there?\\n\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the label is an index. In order to **understand what these labels mean**, we need to extract the class to index mapping. Can you investigate `dir(data)` to find the attrbiute that stores this map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What is the class label to index mapping?\")\n",
    "### YOUR CODE HERE: call the right attribute of data, i.e, data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the images in each of these category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx_map = defaultdict(list)\n",
    "for idx in range(len(data)):\n",
    "    label_idx_map[data[idx][1]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_class = 5\n",
    "n_classes = len(data.class_to_idx)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_classes, ncols=n_samples_per_class , figsize=(10,10), dpi=100)\n",
    "\n",
    "reverse_label_map = {idx:label for label, idx in data.class_to_idx.items()}\n",
    "for row in range(n_classes):\n",
    "    label = reverse_label_map[row]\n",
    "    sample_img_idx = np.random.choice(label_idx_map[row], size=n_samples_per_class)\n",
    "    \n",
    "    axs[row][0].set_ylabel(label, fontweight='bold', rotation=0, labelpad=75)\n",
    "    for j, img_idx in enumerate(sample_img_idx):\n",
    "        ax = axs[row][j]\n",
    "        ax.imshow(\n",
    "            ## YOUR CODE HERE: USE THE RIGHT INDEXING FOR DATA ## \n",
    "        )\n",
    "        ax.axis('off')\n",
    "    \n",
    "    axs[row][0].axis('on')\n",
    "    axs[row][0].xaxis.set_ticks([])\n",
    "    axs[row][0].yaxis.set_ticks([])\n",
    "    \n",
    "_ = fig.suptitle(\"EuroSAT dataset samples per class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for training, validation and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in evaluating the generalization performance of the models, we will split the dataset into train and test datasets. \n",
    "We will use the train dataset to train the models and use the test datasets to evaluate the performance of these models. \n",
    "As per the standard practice, we will apply the normalization procedure as infered from the train dataset to the test dataset at the evaluation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split indices into train, val, and test indices\n",
    "TRAIN_SPLIT=0.6\n",
    "VAL_SPLIT=0.2\n",
    "TEST_SPLIT=0.2\n",
    "train_idxs, val_idxs, test_idxs = ## YOUR CODE HERE: use torch.utils.data.random_split to get indices for each of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert PIL image to a numpy arrray using `np.asarray`, and compute the means and standard deviation across the RGB channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.stack([torch.tensor(np.asarray(data[idx][0])) for idx in train_idxs.indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MEANS =  (X_train / 255.0).mean(axis=(0,1,2)) # to compute mean per channel, we will reduce the other dimensions\n",
    "DATA_STD = (X_train / 255.0).std(axis=(0,1,2)) # to compute mean per channel, we will reduce the other dimensions\n",
    "\n",
    "print(f\"data means along three dimensions: {DATA_MEANS}\")\n",
    "print(f\"data std along three dimensions: {DATA_STD}\")\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=DATA_MEANS, std=DATA_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply `data_transforms` before the data is loaded. To do so, we need to create a `torch.utils.data.Dataset` class that can load individual observations and transform them before giving them to `torch.utils.data.DataLoader` that batches these observations together. \n",
    "\n",
    "Each of the custom `torch.utils.data.Dataset` classes, require the user to define `__getitem__` function to retrieve a single observation at `index` and `__len__` function to return the total number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, indices, transform):\n",
    "        self.data = data\n",
    "        self.subset_idxs = indices\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.data[\n",
    "            ## YOUR CODE HERE: Use the correct indexing \n",
    "        ]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.subset_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data  = TransformedData(data, val_idxs.indices, data_transforms)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=256)\n",
    "\n",
    "test_data = TransformedData(data, test_idxs.indices, data_transforms)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self, c_in, num_classes):\n",
    "        super().__init__()\n",
    "        self.input_args = [c_in, num_classes]\n",
    "        \n",
    "        # READ THROUGH THE CODE TO UNDERSTAND THE MODEL. This is similar to AlexNet.\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),        \n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),        \n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1,1)), # kernel_size and stride are automatically inferred: https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(16, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv4(self.conv3(self.conv2(self.conv1(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write the standard functions to retrieve the attributes of the model, e.g., memory requirements, number of parameters, sparsity in the layers, and global sparsity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: '_orig' in the if-else conditions. It will become clear in the section B of this tutorial. \n",
    "def mem_size(model):\n",
    "    \"\"\"\n",
    "    Get model size in GB (as str: \"N GB\")\n",
    "    \"\"\"\n",
    "    mem_params = sum(\n",
    "        [param.nelement() * param.element_size() for param in model.parameters()]\n",
    "    )\n",
    "    mem_bufs = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "    mem = mem_params + mem_bufs\n",
    "    return f\"{mem / 1e9:.4f} GB\"\n",
    "\n",
    "def num_params(model):\n",
    "    \"\"\"\n",
    "    Print number of parameters in model's named children\n",
    "    and total\n",
    "    \"\"\"\n",
    "    s = \"Number of parameters (sparsity):\\n\"\n",
    "    named_buffers = dict(model.named_buffers())\n",
    "    n_params = 0\n",
    "    for name, child in model.named_children():\n",
    "        n = sum(p.numel() for p in child.parameters())\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        nz = 0\n",
    "        for child_name, p in child.named_parameters():\n",
    "            if '_orig' in child_name:\n",
    "                nz +=  torch.sum(named_buffers[f\"{name}.{child_name.replace('_orig', '_mask')}\"]).item()\n",
    "            else:\n",
    "                nz += torch.sum(p!=0).item()\n",
    "#         nz = sum(torch.count_nonzero(p) for p in child.parameters())\n",
    "        sparsity = (n-nz)/n\n",
    "        s += f\"  • {name:<15}: {n} \\t {sparsity*100:2.3f}%\\n\"\n",
    "        n_params += n\n",
    "    s += f\"{'total':<19}: {n_params}\"\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def compute_sparsity(model):\n",
    "    \"\"\"\n",
    "    Computes global sparsity for the model.\n",
    "    \"\"\"\n",
    "    named_buffers = dict(model.named_buffers())\n",
    "    total_nnz, total_params = 0, 0\n",
    "    for n, p in model.named_parameters():\n",
    "        total_params += p.numel()\n",
    "        \n",
    "        if '_orig' in n:\n",
    "            total_nnz += torch.sum(named_buffers[n.replace('_orig', '_mask')]).item()\n",
    "        else:\n",
    "            total_nnz += torch.sum(p!=0).item()\n",
    "\n",
    "    return (total_params - total_nnz) / total_params\n",
    "\n",
    "\n",
    "def pp_model_summary(model):\n",
    "    print(num_params(model))\n",
    "    print(f\"{'Total memory':<18} : {mem_size(model)}\")\n",
    "    \n",
    "    sparsity = compute_sparsity(model)\n",
    "    print(f\"{'Global sparsity':<18} : {100*sparsity: 2.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model and print it's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepCNN(3, 10)\n",
    "pp_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a standard training function that can be called on `model`. Rest of the arguments are intended for retraining the pruned model as mentioned in the docstring. Note that this setup is quite standard, and you might have followed it in the previous courses (e.g., Modern Network Architecture, Denoising Autoencoders, Attention is all you need, Deep Autoencoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, save_with_pruned_postfix=\"\",n_epochs=100, print_every=1):\n",
    "    \"\"\"Trains the model. \n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): model to be trained \n",
    "        save_with_pruned_postfix (str): The best model is saved with this as postfix\n",
    "        n_epochs (int): maximum number of epochs to run\n",
    "        print_every (int): print performance at every these number of epochs\n",
    "    \n",
    "    Returns:\n",
    "        model (torch.nn.Module): best perforrming model \n",
    "        metrics (dict): metrics, e.g., losses, accuracy, etc.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    pruning_postfix = f\"_prune_{save_with_pruned_postfix}\" if save_with_pruned_postfix else \"\"\n",
    "    \n",
    "    # fix seed for reproducibility \n",
    "    rng = np.random.RandomState(1)\n",
    "    torch.manual_seed(rng.randint(np.iinfo(int).max))\n",
    "    \n",
    "    # create a model directory to store the best model\n",
    "    model_dir = pathlib.Path(\"./models\").resolve()\n",
    "    if not model_dir.exists():\n",
    "        model_dir.mkdir()\n",
    "        \n",
    "    epoch_size=n_epochs\n",
    "    batch_size=64\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    best_val_acc = 0\n",
    "    no_improvement_count = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # training loss \n",
    "        epoch_indices = rng.choice(train_idxs.indices, epoch_size * batch_size, replace=True)\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            ## YOUR CODE HERE: Specify the transformed dataset here\n",
    "            batch_size=batch_size, \n",
    "            num_workers=4)\n",
    "        train_loss, train_acc = process(model, train_dataloader, optimizer)\n",
    "        \n",
    "        # validation loss \n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = process(model, val_dataloader, optimizer=None)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict()\n",
    "            }, model_dir / f\"best_{model.__class__.__name__}{pruning_postfix}.ckpt\")\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            \n",
    "            if no_improvement_count % 10 == 0:\n",
    "                print(\"Early stopping...\")\n",
    "                break\n",
    "        \n",
    "        # logging \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)  \n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            print(f\"Epoch: {epoch}\\t train loss:{train_loss: 0.5f}\\t train acc: {100*train_acc:2.3f}%\\t val_loss:{val_loss:0.5f}\\t val_acc:{100*val_acc:2.3f}%\")\n",
    "        \n",
    "    print(f\"best val acc: {best_val_acc:0.3f}\")\n",
    "\n",
    "    # load the best model\n",
    "    model = model.__class__(*model.input_args)\n",
    "    if save_with_pruned_postfix:\n",
    "        apply_mask_to_loaded_model(model) # a freshly initalized model doesn't \n",
    "    model.load_state_dict(torch.load(model_dir /  f\"best_{model.__class__.__name__}{pruning_postfix}.ckpt\")['model_state'])\n",
    "    model = model.to(device) \n",
    "    \n",
    "    metrics = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs\n",
    "    }\n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, dataloader, optimizer=None):\n",
    "    n_samples = 0\n",
    "    running_loss, running_acc = 0, 0\n",
    "    for batch, labels in dataloader:\n",
    "        # transfer to GPU if avaiable\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        n_samples += batch.shape[0]\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(batch)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        \n",
    "        # backward pass \n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_acc += (preds == labels).sum().float().item()\n",
    "        \n",
    "    return running_loss / n_samples, running_acc / n_samples\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This section can be skipped. The trained model will be provided in `./models` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, metrics = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "def load_unpruned_model():\n",
    "    model = DeepCNN(3, 10)\n",
    "    model_dir = pathlib.Path(\"./models\").resolve()\n",
    "    model = model.__class__(*model.input_args)\n",
    "    model.load_state_dict(torch.load(model_dir /  f\"best_{model.__class__.__name__}.ckpt\")['model_state'])\n",
    "    model = model.to(device) \n",
    "    return model\n",
    "\n",
    "def compute_test_accuracy(model):\n",
    "    ## YOUR CODE HERE\n",
    "    return test_acc\n",
    "\n",
    "model = load_unpruned_model()\n",
    "unpruned_test_acc = compute_test_accuracy(model)\n",
    "\n",
    "# \n",
    "print(f\"Test accuracy of unpruned model:{unpruned_test_acc * 100:2.3f}%\")\n",
    "pp_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Network Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**How pruning is implemented PyTorch code?**\n",
    "\n",
    "Recall that PyTorch stores its weights in `model.state_dict()`. PyTorch's pruning module changes the `model.state_dict()`. Specifically, it acts on the parameters defined by the `name` (e.g., `weight`, `bias`) attribute of the `module` (e.g., `nn.Linear` layer defined in `model`). During pruning, it computes a pruning mask, such that the weights to be pruned are assigned a value of 0. This mask is stored in `model.named_buffers()` with the key as `name_mask` (e.g., `weight_mask`, or `bias_mask`). At the same time, `model.state_dict()` now changes the corresponding key to `name_orig` (e.g., `weight_orig` or `bias_orig`), which stores the origin unpruned weights. At the run time, when the `model.forward` is called, the mask is applied to the unpruned weights. \n",
    "\n",
    "**What are the implications of such an implementation?**\n",
    "\n",
    "1. **Size of the model**: Unless the `name_mask` parameters are removed, the size of the model will only grow. Thus, after pruning is complete, one can call `prune.remove` to thrrow away masks and store the weights to their pruned values. \n",
    "\n",
    "2. **Iterative pruning**: Every pruning iteration will create it's own mask. Thus, nothing special needs to be done. These masks are stored in a list as `module._forward_pre_hooks.values()`. \n",
    "\n",
    "3. **Saving a pruned model**: As explained above, pruned models carry masks with them. Thus, the pruned models need to be saved with their entire state if they are to be used later (e.g., after the pre-empted training). In our tutorial, we will only be saving `model.state_dict()`, however, in practice, you would want to save `model.named_buffers()` too. \n",
    "\n",
    "4. **Loading a pruned model**: Loading a pruned model follows a slightly different procedure as well. An unpruned model will not have any `name_orig` in their keys. However, the `state_dict` of the pruned model will contain such keys. Hence, the loading procedure will complain. Therefore, one needs to use `prune.identity` on these keys to tell PyTorch that these parameters were being pruned. \n",
    "\n",
    "**Telling PyTorch which layers to prune**\n",
    "\n",
    "`prune` requires the user to specify which layers and what type parameters (e.g., `weight` or `biases`) are to be pruned. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "In our tutorial, we will focus our pruning efforts only on the convolutional layers defined in `model.conv1`, `model.conv2`, `model.conv3`, and `model.conv4`. And we will focus only on `weight` parameters of these layers. \n",
    "\n",
    "**Note**: Each of these `conv` layers are defined as `nn.Sequential` which can be treated as a `list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_to_prune(model):\n",
    "    \"\"\"Returns the list of (module, name) in model to be pruned.\"\"\"\n",
    "    return [\n",
    "        ## YOUR CODE HERE: Pass the tuple of (module, name) here to be used in the code cells below. \n",
    "        ## Pass such tuples for kernel weights in model.conv1, model.conv2, model.conv3, model.conv4. \n",
    "        ## There will be a total of 4 tuples.\n",
    "    ]\n",
    "\n",
    "def apply_mask_to_loaded_model(model):\n",
    "    \"\"\"\n",
    "    Applies `prune.identity` to the freshly loaded model that was pruned earlier. \n",
    "    `prune.identity` tells `torch` which weights are in the process of being pruned, and hence need to be trated differrently.\n",
    "    \"\"\"\n",
    "    m_weights_to_prune = get_weights_to_prune(model)\n",
    "    for module, name in m_weights_to_prune:\n",
    "        prune.identity(module=module, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random unstructured pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a starting example, we will randomly prune weights in an unstructured fashion. To do so, we will use `prune.random_unstructured` functionality to define which modules and what parameters are to be pruned. Read the more [here](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#pruning-a-module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_to_prune = get_weights_to_prune(model)\n",
    "\n",
    "PRUNE_RATE=0.3\n",
    "for module, name in weights_to_prune:\n",
    "    prune.random_unstructured(\n",
    "        ## YOUR CODE HERE: read the documentation above\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the sparsity induced by above pruning and the resulting test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_test_acc = compute_test_accuracy(model)\n",
    "print(f\"Pruned test acc: {100*pruned_test_acc: 2.3f}%\")\n",
    "pp_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the pruned mdoel and observe the effect on the test accuracy?\n",
    "\n",
    "**Q.** Does the test accuracy increase or decrease? Can you reason why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrained_model, _ = train(model, save_with_pruned_postfix=f\"random_unstructured_{PRUNE_RATE}\", n_epochs=50, print_every=10)\n",
    "pruned_test_acc = compute_test_accuracy(retrained_model)\n",
    "print(f\"Pruned test acc: {100*pruned_test_acc: 2.3f}%\")\n",
    "pp_model_summary(retrained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, pruning is applied iterative. For this tutorial, we will apply pruning twice before jumping to other methods.\n",
    "\n",
    "**Q.** How does the performance vary in this iteration? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_to_prune = get_weights_to_prune(retrained_model)\n",
    "for module, name in weights_to_prune:\n",
    "    prune.random_unstructured(\n",
    "        ## YOUR CODE HERE: read the documentation above\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Iteration #2: \\n\")\n",
    "\n",
    "# before finetuning\n",
    "pruned_test_acc = compute_test_accuracy(retrained_model)\n",
    "print(f\"Pruned test acc: {100*pruned_test_acc: 2.3f}%\")\n",
    "pp_model_summary(retrained_model)\n",
    "\n",
    "# after finetuning\n",
    "retrained_model, _ = train(retrained_model, save_with_pruned_postfix=f\"random_unstructured_{PRUNE_RATE}_#2\", n_epochs=50, print_every=10)\n",
    "pruned_test_acc = compute_test_accuracy(retrained_model)\n",
    "print(f\"Pruned test acc: {100*pruned_test_acc: 2.3f}%\")\n",
    "pp_model_summary(retrained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Unstructured (local)\n",
    "\n",
    "To prune the weights with lowest magnitude (i.e., L1-norm), use the `prune.11_unstructured`. Read more at the [documentation here](https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Structured (local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prune.ln_structured` lets the user define the dimension along which norm is to be computed. Thus, if the CNN weights are of shape `[3, 32, 32]` and we want to eliminate some filters, i.e., channels in dimension 0, the function expects an argument `dim` corresponding to that. [Read more about the function here](https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.ln_structured.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Unstructured (global)\n",
    "\n",
    "Finally, `prune.global_unstructured` can apply the prune rate globally across the specified modules. [Read its documentation here](https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_unpruned_model()\n",
    "unpruned_test_acc = compute_test_accuracy(model)\n",
    "\n",
    "PRUNE_RATES = [0.3, 0.5, 0.7]\n",
    "N_RETRAINING_EPOCHS = 15\n",
    "PRINT_EVERY=N_RETRAINING_EPOCHS//3\n",
    "\n",
    "# random unstructured pruning \n",
    "print(\"\\nRandom Unstructured (local)\\n\")\n",
    "random_unstructured_performance = []\n",
    "for prune_rate in PRUNE_RATES:\n",
    "    model = load_unpruned_model()\n",
    "    weights_to_prune = get_weights_to_prune(model)\n",
    "    for module, name in weights_to_prune:\n",
    "        prune.random_unstructured(\n",
    "            ## YOUR CODE HERE: read the documentation above\n",
    "        )\n",
    "    \n",
    "    retrained_model, _ = train(model, save_with_pruned_postfix=f\"random_unstructured_{prune_rate}\", n_epochs=N_RETRAINING_EPOCHS, print_every=PRINT_EVERY)\n",
    "    sparsity = compute_sparsity(retrained_model)\n",
    "    test_acc = compute_test_accuracy(retrained_model)\n",
    "    \n",
    "    random_unstructured_performance.append((sparsity, test_acc))\n",
    "\n",
    "\n",
    "# l1 unstructured pruning (local)\n",
    "print(\"\\nL1 Unstructured (local)\\n\")\n",
    "l1_unstructured_performance = []\n",
    "for prune_rate in PRUNE_RATES:\n",
    "    model = load_unpruned_model()\n",
    "    weights_to_prune = get_weights_to_prune(model)\n",
    "    for module, name in weights_to_prune:\n",
    "        prune.l1_unstructured(\n",
    "            ## YOUR CODE HERE: read the documentation above\n",
    "        )\n",
    "    \n",
    "    retrained_model, _ = train(model, save_with_pruned_postfix=f\"l1_unstructured_{prune_rate}\", n_epochs=N_RETRAINING_EPOCHS, print_every=PRINT_EVERY)\n",
    "    sparsity = compute_sparsity(retrained_model)\n",
    "    test_acc = compute_test_accuracy(retrained_model)\n",
    "    \n",
    "    l1_unstructured_performance.append((sparsity, test_acc))\n",
    "\n",
    "# l1 unstructured pruning (global)\n",
    "print(\"\\nL1 Unstructured (global)\\n\")\n",
    "l1_unstructured_global_performance = []\n",
    "for prune_rate in PRUNE_RATES:\n",
    "    model = load_unpruned_model()\n",
    "    weights_to_prune = get_weights_to_prune(model)\n",
    "    prune.global_unstructured(\n",
    "        ## YOUR CODE HERE: read the documentation above\n",
    "    )\n",
    "    \n",
    "    retrained_model, _ = train(model, save_with_pruned_postfix=f\"l1_unstructured_global_{prune_rate}\", n_epochs=N_RETRAINING_EPOCHS, print_every=PRINT_EVERY)\n",
    "    sparsity = compute_sparsity(retrained_model)\n",
    "    test_acc = compute_test_accuracy(retrained_model)\n",
    "    \n",
    "    l1_unstructured_global_performance.append((sparsity, test_acc))\n",
    "\n",
    "\n",
    "# l1 structured pruning (local) \n",
    "print(\"\\nL1 structured\\n\")\n",
    "l1_structured_performance = []\n",
    "for prune_rate in PRUNE_RATES:\n",
    "    model = load_unpruned_model()\n",
    "    weights_to_prune = get_weights_to_prune(model)\n",
    "    for module, name in weights_to_prune:\n",
    "        prune.ln_structured(\n",
    "            ## YOUR CODE HERE: read the documentation above\n",
    "        )\n",
    "\n",
    "    \n",
    "    retrained_model, _ = train(model, save_with_pruned_postfix=f\"l1_structured_{prune_rate}\", n_epochs=N_RETRAINING_EPOCHS, print_every=PRINT_EVERY)\n",
    "    sparsity = compute_sparsity(retrained_model)\n",
    "    test_acc = compute_test_accuracy(retrained_model)\n",
    "    \n",
    "    l1_structured_performance.append((sparsity, test_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot various performances\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1, nrows=1, figsize=(12,6), dpi=100)\n",
    "\n",
    "# unpruned model \n",
    "axs.hlines(y=unpruned_test_acc, xmin=0, xmax=1, linestyles=\"--\", colors='#E8384F', linewidth=2)\n",
    "\n",
    "# random unstructured\n",
    "x,y = zip(*random_unstructured_performance)\n",
    "axs.plot(x, y, color=\"#208EA3\", linestyle=\":\", marker=\"o\", label=\"random unstructured\", linewidth=2)\n",
    "\n",
    "# l1 unstructured (local)\n",
    "x,y = zip(*l1_unstructured_performance)\n",
    "axs.plot(x, y, color=\"#A4C61A\", linestyle=\":\", marker=\"o\", label=\"l1 unstructured\", linewidth=2)\n",
    "\n",
    "\n",
    "# l1 unstructured (global)\n",
    "x,y = zip(*l1_unstructured_global_performance)\n",
    "axs.plot(x, y, color=\"#8D9F9B\", linestyle=\":\", marker=\"o\", label=\"l1 unstructured (global)\", linewidth=2)\n",
    "\n",
    "\n",
    "# l1 structured\n",
    "x,y = zip(*l1_structured_performance)\n",
    "axs.plot(x, y, color=\"#37A862\", linestyle=\":\", marker=\"o\", label=\"l1 structured\", linewidth=2)\n",
    "\n",
    "axs.set_ylabel(\"Test accuracy\", fontsize=20)\n",
    "axs.set_xlabel(\"Sparsity\", fontsize=20)\n",
    "\n",
    "# tick size\n",
    "for tick in axs.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(15)\n",
    "\n",
    "for tick in axs.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(15)\n",
    "\n",
    "axs.set_xlim(0,1)\n",
    "axs.grid(True, linestyle=':')\n",
    "\n",
    "# legend\n",
    "\n",
    "legend = []\n",
    "legend.append(Line2D([0,1], [1,0], color=\"#E8384F\", label=\"Unpruned model\", linewidth=5))\n",
    "legend.append(Line2D([0,1], [1,0], color=\"#208EA3\", label=\"Random Unstructured\", linewidth=5))\n",
    "legend.append(Line2D([0,1], [1,0], color=\"#A4C61A\", label=\"L1 Unstructured\", linewidth=5))\n",
    "legend.append(Line2D([0,1], [1,0], color=\"#8D9F9B\", label=\"L1 Unstructured (global)\", linewidth=5))\n",
    "legend.append(Line2D([0,1], [1,0], color=\"#37A862\", label=\"L1 Structured\", linewidth=5))\n",
    "lgd = fig.legend(handles=legend, ncol=1, fontsize=15, loc=\"center right\", fancybox=True, bbox_to_anchor=(1.0, 0.5, 0.2, 0))\n",
    "\n",
    "\n",
    "_ = fig.suptitle(\"Sparsity-Accuracy Tradeoff\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a pruned model \n",
    "\n",
    "To reduce the size of the pruned model, we remove the masks in `model.state_dict()`. This is convenientyl done by `prune.remove(module, name)`. Read more about it [here](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#remove-pruning-re-parametrization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom pruning method \n",
    "\n",
    "Applying a pruning method requires defining computing mask. This can be done through a custom class. See [here](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#extending-torch-nn-utils-prune-with-custom-pruning-functions) to learn how to extend pruning method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc",
   "language": "python",
   "name": "dlc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
