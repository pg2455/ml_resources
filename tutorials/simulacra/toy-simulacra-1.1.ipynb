{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e096cb-6637-4631-a5a2-466160ee9a49",
   "metadata": {},
   "source": [
    "# Toy Simulacra 1.1\n",
    "\n",
    "This is the first in a series of four notebooks designed to build a simplified version of Simulacra [1]. While the original Simulacra encompasses a broader range of components facilitating comprehensive simulations, this tutorial series aims to familiarize the audience with the implementation of generative agents and the application of Language Learning Models (LLMs) in sociological simulations.\n",
    "\n",
    "For additional insights into how this tutorial is organized and some overarching considerations in constructing simulations with LLMs, I invite you to read a retrospective on my [blog](https://www.pgupta.info/blog).\n",
    "\n",
    "[[[1] Park et al. 2023 Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)\n",
    "\n",
    "Note: Parts of this tutorial series have been refined using LLMs, guided by prompts like \"Proofread and correct --\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d18a91-3d59-43e4-838f-3bedc432f175",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this part of our tutorial, we’ll focus on understanding how to interact with the simulated environment, setting aside the complexities of agent-specific details. To facilitate this, we'll introduce a dummy agent for the purposes of demonstration.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6cb5e19-fda0-4fd3-82ed-a3d952b652cc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Important Note:** For those who prefer running the code via the command line rather than navigating through notebook cells—which can become tedious due to the volume of code in subsequent notebooks—I've made the entire codebase available [here](https://github.com/pg2455/toy-simulacra).\n",
    "\n",
    "### Requirements:\n",
    "- **OpenAI Library**: Install using the command `pip install openai`.\n",
    "- **GPT Keys**: Required for sections 1.3 and 1.4 to interact with LLMs.\n",
    "\n",
    "**Additional Note:** While this tutorial is crafted around the use of GPT, it's adaptable to other LLMs. Should you choose to use an alternative LLM, simply adjust the `PROMPT_FN` in notebooks 1.3 and 1.4. Anticipate approximately 1000 calls to the LLMs for a simulation spanning 1.5 simulation days.\n",
    "\n",
    "### Getting Started:\n",
    "\n",
    "1. Clone the original repository to access the necessary files:\n",
    "   ```bash\n",
    "   git clone https://github.com/joonspk-research/generative_agents.git\n",
    "   ```\n",
    "2. Copy the relevant files into your current working directory:\n",
    "   ```bash\n",
    "   cp ./generative_agents/reverie/backend_server/maze.py .\n",
    "   cp ./generative_agents/reverie/backend_server/global_methods.py .\n",
    "   cp ./generative_agents/reverie/backend_server/utils.py .\n",
    "   ```\n",
    "Alternatively, execute the code block provided to automate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b90c8c-626d-431f-8f9f-8d972e5024fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/joonspk-research/generative_agents.git\n",
    "!cp ./generative_agents/reverie/backend_server/maze.py . \n",
    "!cp ./generative_agents/reverie/backend_server/global_methods.py . \n",
    "!cp ./generative_agents/reverie/backend_server/utils.py . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1889f3d4-d4cc-4b78-9d5e-5d53a82d7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime, timedelta\n",
    "from maze import Maze\n",
    "\n",
    "BASE_SIM_FOLDER = Path(\"./generative_agents/environment/frontend_server/storage/base_the_ville_isabella_maria_klaus/\").resolve()\n",
    "PERSONAS_FOLDER = BASE_SIM_FOLDER / \"personas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0c81d-431e-4d88-b07b-21460d1a2bee",
   "metadata": {},
   "source": [
    "## Environment: The Maze\n",
    "\n",
    "The environment is encapsulated within the `Maze` class, found in `maze.py`. This class is designed to be straightforward, offering functionalities to:\n",
    "- Interact with the environment,\n",
    "- Store the current state of the environment, and\n",
    "- Provide access to various aspects of itself.\n",
    "\n",
    "Utilizing these functions, we'll explore how to manage interactions between our dummy agent and the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8401f6-7ca9-4a36-9207-d02888e34fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height:100\tWidth140\n"
     ]
    }
   ],
   "source": [
    "maze = Maze(\"the Ville\")\n",
    "\n",
    "print(f\"Height:{maze.maze_height}\\tWidth{maze.maze_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bab9814-0219-430e-b16f-abf2587e635c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71, 13),\n",
       " (71, 14),\n",
       " (71, 15),\n",
       " (72, 13),\n",
       " (72, 14),\n",
       " (72, 15),\n",
       " (73, 13),\n",
       " (73, 14),\n",
       " (73, 15)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the nearby tiles (vision_r defines the radius around the coordinate)\n",
    "maze.get_nearby_tiles([72,14], vision_r=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ab09a-5b17-4b83-8327-a34d93794c1d",
   "metadata": {},
   "source": [
    "Each tile has a string address in addition to the numerical coordinates. \n",
    "This string address is created as such: World name: Sector name: Arena name: Object name\n",
    "\n",
    "World name is the name of the environment. This will be constant across all the tiles. \n",
    "Sector name is the name of the block for example school or cafe\n",
    "Arena name is the name of the small sub sections for example rooom in a cafe, etc. \n",
    "Object name is the name of the object on that tile (if any) such as desk, table etc. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444d4b6b-966e-407f-a563-f1ad87f49bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the Ville:Isabella Rodriguez's apartment:main room:bed\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the string address of the tile\n",
    "# World: Sector (e.g., house, cafe): Arena (e.g., designated area within sector): object (An actual object, e.g., bed, table, etc.)\n",
    "maze.get_tile_path([72, 14], level='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e90143-32a2-4c87-bb62-cffc80f5a4e4",
   "metadata": {},
   "source": [
    "## Events\n",
    "\n",
    "Events represent perceptions that are shared between agents and the environment, as well as among the agents themselves. They can be as varied as \"The piano is occupied\" or \"Maria is chatting with Isabella.\" These shared perceptions will be elaborated upon through `ConceptNode` in the next notebook, where it will become apparent that events encapsulate more than just textual descriptions.\n",
    "\n",
    "Defined by a structure (subject, predicate, object, description), events also possess additional attributes such as the time of creation, expiration, and embeddings. These embeddings play a crucial role in the simulation, particularly in determining an event’s relevance to specific queries, for instance, by calculating the cosine similarity with a query’s embedding. This process will be detailed in Notebook 1.3.\n",
    "\n",
    "While the original Simulacra code distinguishes between chats, thoughts, and environmental events, for ease of understanding, we have consolidated these distinctions into a singular concept of 'events'. This approach simplifies the code and will be explored further in the forthcoming notebook.\n",
    "\n",
    "Lastly, when an event is associated with a specific location in the environment, each corresponding tile records the event. Thus, when an agent perceives a tile within its perception radius, the event is registered in the agent's short-term memory, seamlessly integrating environmental dynamics with individual agent experiences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed9089f-8b08-4899-8a58-1f44ddf7eee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'world': 'the Ville',\n",
       " 'sector': \"Isabella Rodriguez's apartment\",\n",
       " 'arena': 'main room',\n",
       " 'game_object': 'bed',\n",
       " 'spawning_location': 'sp-A',\n",
       " 'collision': False,\n",
       " 'events': {(\"the Ville:Isabella Rodriguez's apartment:main room:bed\",\n",
       "   None,\n",
       "   None,\n",
       "   None)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a more detailed information about a specific tile\n",
    "# Note: collision defines whether there is a wall or an object that can block person's path\n",
    "# Note: events is a set that determines all events on that tile. By default, tile_path is the event. See below for events.\n",
    "maze.access_tile([72, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec60f13-c4e1-4709-ab1d-cc2aaa92d8c1",
   "metadata": {},
   "source": [
    "## Persona\n",
    "\n",
    "Following our exploration of the Maze, we now turn our attention to the Persona class, which encapsulates the essence of a generative agent. This class is integral to crafting \"believably human\" behaviors by enabling agents to perform actions, exhibit behaviors, and make plans that are consistent with their characters. In this discussion, we will introduce dummy versions of the various memory structures utilized by Simulacra, rather than delving into their intricate details:\n",
    "\n",
    "- **SpatialMemoryTree**: A structure that represents the agent's knowledge of the environment.\n",
    "- **AssociativeMemory**: A repository for the agent's thoughts, conversations, and events, encapsulating their experiences.\n",
    "- **Scratch (Short-Term Memory)**: A class for storing transient information, such as daily plans, current actions, and identity details like agendas and intended paths.\n",
    "\n",
    "In the subsequent notebook, we'll delve deeper into these constituent classes, further illustrating its role in simulating human-like behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba300629-411b-420f-ad0a-f527e3c23d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch:\n",
    "    def __init__(self, fname):\n",
    "        self.name = \"dummy\"\n",
    "        self.curr_time = None\n",
    "        self.curr_tile = [72, 14]\n",
    "\n",
    "    def get_curr_event_and_desc(self):\n",
    "        return (self.name, None, None, None)\n",
    "\n",
    "class AssociativeMemory:\n",
    "    def __init__(self, fname):\n",
    "        pass\n",
    "\n",
    "class SpatialMemoryTree:\n",
    "    def __init__(self, fnam):\n",
    "        pass\n",
    "\n",
    "class Persona:\n",
    "    def __init__(self, name, folder_mem, curr_time, initiate_plan=True):\n",
    "        self.name = name\n",
    "        self.s_mem = None \n",
    "        self.a_mem = None\n",
    "        self.scratch = Scratch(f\"{folder_mem}/bootstrap_memory/scratch.json\")\n",
    "        self.s_mem = SpatialMemoryTree(f\"{folder_mem}/bootstrap_memory/scratch.json\")\n",
    "        self.a_mem = AssociativeMemory(f\"{folder_mem}/bootstrap_memory/scratch.json\")\n",
    "        self.scratch.curr_time = curr_time\n",
    "        \n",
    "        if initiate_plan:\n",
    "            self.generate_day_plan()\n",
    "\n",
    "    def generate_day_plan(self):\n",
    "        pass\n",
    "\n",
    "    def perceive_and_retrieve_and_focus(self):\n",
    "        pass\n",
    "\n",
    "    def advance_one_step(self, maze, personas, curr_time):\n",
    "        x = self.get_curr_tile()\n",
    "        # Randomly generating new tile\n",
    "        new_tile = [x[0]+random.randint(-5, 5), x[1]+random.randint(-5, 5)]\n",
    "        return new_tile\n",
    "\n",
    "    def get_curr_tile(self):\n",
    "        return self.scratch.curr_tile\n",
    "\n",
    "    def move(self, new_tile):\n",
    "        self.scratch.curr_tile = new_tile\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7fe64-17a1-4771-90fb-0f8baba643db",
   "metadata": {},
   "source": [
    "### Simulation loop\n",
    "\n",
    "Finally, we need a simulation clock that can keep itself turning every regular interval. We chose this interval based on our required precision. For this tutorial, I have chosen it to be 10 minutes per simulation iteration. Thus, each simulation iteration is akin to 10 minutes real time. \n",
    "\n",
    "This is done in the main loop, where we keep advancing the simulation clock and between each tick, we check on each agent and advance them one by one - perceiving the world around them, enchancing their memories, taking actions, adapting their plans along the way. \n",
    "\n",
    "Note we iterate through the agents twice. This is so that within the same iteration, perception should be symmetric. If we move the agent in the first iteration, that agent might not be visible to the other agents in the same iteration (leading to asymmetric perception). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ab8eba-e7ad-4492-bc2b-7d4c41f46a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00 Klaus Mueller [72, 16]\n",
      "00:00 Isabella Rodriguez [67, 14]\n",
      "00:00 Maria Lopez [70, 9]\n",
      "00:10 Klaus Mueller [77, 21]\n",
      "00:10 Isabella Rodriguez [72, 17]\n",
      "00:10 Maria Lopez [70, 12]\n",
      "00:20 Klaus Mueller [74, 26]\n",
      "00:20 Isabella Rodriguez [77, 18]\n",
      "00:20 Maria Lopez [68, 11]\n",
      "00:30 Klaus Mueller [75, 29]\n",
      "00:30 Isabella Rodriguez [82, 13]\n",
      "00:30 Maria Lopez [70, 7]\n",
      "00:40 Klaus Mueller [79, 29]\n",
      "00:40 Isabella Rodriguez [80, 8]\n",
      "00:40 Maria Lopez [66, 8]\n"
     ]
    }
   ],
   "source": [
    "maze = Maze(\"the Ville\")\n",
    "curr_time = sim_start_time = datetime(2024, 2, 13, 0, 0, 0) # Start at midnight\n",
    "seconds_per_step = 10 * 60 # 10 minutes\n",
    "n_steps = 5\n",
    "\n",
    "personas = []\n",
    "for persona_folder in PERSONAS_FOLDER.iterdir():\n",
    "    personas.append(Persona(persona_folder.name, persona_folder, curr_time, initiate_plan=True))\n",
    "\n",
    "step = 0\n",
    "movements = {}\n",
    "while step < n_steps:\n",
    "\n",
    "    for persona in personas:\n",
    "        curr_tile = persona.get_curr_tile()\n",
    "        new_tile = persona.advance_one_step(maze, personas, curr_time)\n",
    "        movements[persona.name] = new_tile\n",
    "\n",
    "    for persona in personas:\n",
    "        new_tile = movements[persona.name]\n",
    "        if new_tile:\n",
    "            maze.remove_subject_events_from_tile(persona.name, curr_tile)\n",
    "            maze.add_event_from_tile(persona.scratch.get_curr_event_and_desc(), new_tile)\n",
    "            persona.move(new_tile)\n",
    "        print(curr_time.strftime(\"%H:%M\"), persona.name, persona.scratch.curr_tile)\n",
    "    \n",
    "    step += 1\n",
    "    curr_time = sim_start_time + timedelta(seconds=seconds_per_step*step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae6cd0-897f-4993-8839-8b8b00e407ae",
   "metadata": {},
   "source": [
    "With the foundational elements of our simulation now established, we're ready to delve deeper into the memory structure in our upcoming notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
